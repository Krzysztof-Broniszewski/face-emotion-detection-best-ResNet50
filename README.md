# ğŸ˜ƒ Face Emotion Detector â€” Best Edition

Real-time facial emotion recognition using a webcam feed, combining **DeepFace**, **OpenCV**, and optional **MediaPipe** rotation alignment for improved accuracy.  
The detector predicts 7 basic emotions directly from the live camera stream and visualizes probabilities with dynamic bars.

---

## ğŸ¥ Demo

### â–¶ï¸ Live Detection Example
![Demo GIF](./Emotion_detector_best_demo.gif)

### ğŸ§  Emotion Samples
| Happy ğŸ˜Š | Angry ğŸ˜¡ |
|-----------|-----------|
| ![Happy](./happy.png) | ![Angry](./angry.png) |

---

## ğŸš€ Features

- âœ… Real-time emotion detection from webcam  
- âœ… Auto fallback from **MediaPipe** to **HaarCascade** if protobuf breaks  
- âœ… Automatic ROI rotation to align eyes horizontally  
- âœ… Smooth temporal averaging (EMA + history buffer)  
- âœ… Stable detection box (IoU + adaptive switching logic)  
- âœ… Always-on-top window mode  
- âœ… Visualization of all emotion probabilities in a side panel  

---

## ğŸ§© Supported Emotions
| # | Emotion   | Description |
|:-:|------------|-------------|
| 1 | ğŸ˜¡ **angry**     | anger, frustration |
| 2 | ğŸ¤¢ **disgust**   | aversion, displeasure |
| 3 | ğŸ˜¨ **fear**      | anxiety, fear |
| 4 | ğŸ˜„ **happy**     | joy, satisfaction |
| 5 | ğŸ˜¢ **sad**       | sadness, sorrow |
| 6 | ğŸ˜² **surprise**  | astonishment |
| 7 | ğŸ˜ **neutral**   | calm, relaxed |

---

## ğŸ§  Model Info

This project uses:
- **DeepFace** backend (`VGG-Face` / `Emotion` model)
- Optional **MediaPipe Face Detection** for bounding boxes and eye rotation
- Fallback to **Haar Cascade** (for stability across TensorFlow / protobuf versions)

---

## âš™ï¸ Installation

Clone the repository and create a Python environment (recommended via `venv` or `conda`):

```bash
git clone https://github.com/<your_username>/face_emotion_detector_best.git
cd face_emotion_detector_best

pip install -r requirements.txt

